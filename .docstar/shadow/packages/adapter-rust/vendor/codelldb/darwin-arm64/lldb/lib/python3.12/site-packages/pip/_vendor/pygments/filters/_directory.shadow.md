# packages/adapter-rust/vendor/codelldb/darwin-arm64/lldb/lib/python3.12/site-packages/pip/_vendor/pygments/filters/
@generated: 2026-02-09T18:16:04Z

## Overall Purpose
This directory implements the Pygments filter system, providing text transformation capabilities for syntax-highlighted code. Filters operate on token streams produced by lexers, enabling post-processing operations like highlighting special comments, converting symbols to Unicode, changing keyword casing, and manipulating whitespace visibility.

## Architecture & Components
The module follows a plugin-based registry pattern with the following key components:

**Filter Registry System**: Central `FILTERS` dictionary maps filter names to implementation classes, with plugin support for extensibility via `find_plugin_filters()`.

**Factory Interface**: `get_filter_by_name()` serves as the primary entry point, instantiating filters by name with configuration options. `find_filter_class()` handles lookup logic across built-in and plugin filters.

**Stream Processing Filters**: All filters implement a common pattern of consuming and yielding `(token_type, value)` tuples from lexer output:
- **CodeTagFilter**: Highlights TODO/FIXME-style tags in comments
- **SymbolFilter**: Mathematical symbol-to-Unicode conversion (LaTeX/Isabelle)
- **KeywordCaseFilter**: Keyword case transformation (upper/lower/capitalize)
- **NameHighlightFilter**: Custom token type assignment for specific identifiers
- **VisibleWhitespaceFilter**: Whitespace visualization with Unicode characters
- **GobbleFilter**: Leading character removal from code lines
- **TokenMergeFilter**: Consecutive same-type token consolidation
- **RaiseOnErrorTokenFilter**: Exception handling for lexer error tokens

## Public API Surface
**Primary Entry Points**:
- `get_filter_by_name(filtername, **options)` - Filter factory function
- `get_all_filters()` - Discovery of available filters
- `find_filter_class(filtername)` - Direct class lookup

**Filter Classes**: All filter implementations are publicly accessible and follow consistent option-based configuration patterns using utility functions like `get_list_opt()` and `get_choice_opt()`.

## Internal Organization
**Data Flow**: Filters integrate into the Pygments pipeline between lexers and formatters, transforming token streams through configurable text processing operations.

**Configuration Pattern**: Filters use standardized option parsing with validation helpers from `pygments.util`, enabling consistent parameter handling across implementations.

**Utility Functions**: `_replace_special()` provides regex-based token replacement functionality shared across multiple filter implementations.

## Key Conventions
- All filters operate on `(token_type, value)` tuple streams
- Option-based configuration with validation
- Plugin architecture for extensibility
- Registry-based discovery and instantiation
- Stream processing with generator patterns for memory efficiency
# packages/adapter-rust/vendor/codelldb/darwin-arm64/lldb/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/
@generated: 2026-02-09T18:16:14Z

## Overall Purpose
This directory contains the core lexer discovery and registry system for Pygments syntax highlighting within pip's vendored dependencies. It serves as the central hub for finding, loading, and instantiating lexers for over 500 programming languages, markup formats, and domain-specific languages.

## Key Components and Architecture

### Core Registry System
- **`_mapping.py`**: Auto-generated registry containing 579+ lexer definitions mapped to their modules, aliases, file patterns, and MIME types
- **`__init__.py`**: Lexer discovery engine with lazy loading, caching, and multiple lookup strategies
- **Language-specific modules** (e.g., `python.py`): Individual lexer implementations for specific languages and dialects

### Lexer Discovery Engine
The `__init__.py` module implements a sophisticated discovery system with multiple entry points:
- **By name/alias**: `get_lexer_by_name()` - Primary API for known languages
- **By filename**: `get_lexer_for_filename()` - File extension/pattern matching
- **By MIME type**: `get_lexer_for_mimetype()` - Content-type based selection
- **By text analysis**: `guess_lexer()` - Intelligent content analysis when other methods fail

### Caching and Performance
- **`_lexer_cache`**: Global cache for loaded lexer classes
- **`_pattern_cache`**: Compiled regex cache for filename patterns
- **Lazy loading**: Lexer modules are imported on-demand via `_load_lexers()`
- **`_automodule`**: Custom module type enabling dynamic attribute access

## Public API Surface

### Primary Entry Points
```python
# Get lexer instance by language name
get_lexer_by_name(alias, **options)

# Get lexer by filename patterns
get_lexer_for_filename(filename, code=None, **options)

# Get lexer by MIME type
get_lexer_for_mimetype(mimetype, **options)

# Intelligent text analysis
guess_lexer(text, **options)
guess_lexer_for_filename(filename, text, **options)
```

### Discovery Functions
```python
# Get lexer classes (no instantiation)
find_lexer_class(name)
find_lexer_class_by_name(alias)
find_lexer_class_for_filename(filename)

# Enumerate all available lexers
get_all_lexers()

# Load custom lexers
load_lexer_from_file(filename, lexername)
```

## Internal Organization and Data Flow

### Lookup Strategy
1. **Built-in lexers**: Check `LEXERS` mapping from `_mapping.py`
2. **Plugin lexers**: Discover third-party lexers via entry points
3. **Fallback**: Raise `ClassNotFound` if no match found

### Text Analysis Pipeline
1. **Filename bonus**: Lexers matching file patterns get priority boost
2. **Content analysis**: Lexers analyze text and return confidence scores (0.0-1.0)
3. **Best match selection**: Highest scoring lexer is selected
4. **Shebang detection**: Special handling for script interpreter hints

### Multi-Variant Language Support
Languages with multiple dialects/versions are handled through:
- **Inheritance hierarchies**: `Python2Lexer` and `PythonLexer` sharing common patterns
- **Specialized lexers**: Console sessions (`PythonConsoleLexer`), tracebacks (`PythonTracebackLexer`)
- **Extension lexers**: Enhanced variants like `NumPyLexer` and `CythonLexer`

## Important Patterns and Conventions

### Lexer Registration
- **5-tuple format**: `(module_path, display_name, aliases, file_patterns, mime_types)`
- **Multiple aliases**: Most lexers support several identification strings
- **Hierarchical modules**: Related lexers grouped by language family

### Error Handling
- **`ClassNotFound`**: Consistent exception for missing lexers
- **Compatibility mapping**: `COMPAT` dict handles deprecated lexer names
- **Graceful degradation**: Text analysis returns scores allowing fallback strategies

### Plugin Architecture
- **Entry point discovery**: Third-party lexers can extend the system
- **Dynamic loading**: Lexers loaded on-demand to minimize memory footprint
- **Module hijacking**: Directory module replaced with dynamic proxy for seamless access

This directory essentially provides a comprehensive language detection and syntax highlighting dispatch system, serving as the foundation for code colorization throughout pip's documentation and output formatting capabilities.
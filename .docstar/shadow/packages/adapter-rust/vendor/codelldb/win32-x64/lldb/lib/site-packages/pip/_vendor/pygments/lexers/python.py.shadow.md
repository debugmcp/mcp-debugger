# packages/adapter-rust/vendor/codelldb/win32-x64/lldb/lib/site-packages/pip/_vendor/pygments/lexers/python.py
@source-hash: 0f37870665b52314
@generated: 2026-02-09T18:02:15Z

This file implements Pygments lexers for Python and related languages. It defines syntax highlighting rules for tokenizing Python source code into semantic tokens for code colorization and analysis.

## Core Components

**PythonLexer (L26-414)**: Main lexer for Python 3.x source code
- Uses RegexLexer base class with comprehensive token rules
- Handles f-strings, raw strings, bytes, and various string formats
- Supports Python 3.x keywords, builtins, exceptions, and magic methods
- Pattern matching support for `match`/`case` statements (soft keywords L221-234)
- Complex string interpolation patterns for old-style (%) and new-style ({}) formatting

**Python2Lexer (L417-637)**: Dedicated lexer for Python 2.x syntax
- Similar structure to PythonLexer but without f-strings
- Includes Python 2-specific features like backticks, `print` as keyword, `long` integers
- Different builtin functions and exception hierarchy

**Console and Traceback Lexers**:
- **PythonConsoleLexer (L674-718)**: Interactive Python session highlighting with `>>>` prompts
- **PythonTracebackLexer (L720-774)**: Python 3.x traceback formatting with chained exception support
- **Python2TracebackLexer (L777-823)**: Python 2.x traceback formatting

**Specialized Lexers**:
- **CythonLexer (L825-1003)**: Pyrex/Cython with C-type annotations and cdef constructs
- **DgLexer (L1005-1102)**: Functional language running on CPython VM
- **NumPyLexer (L1104-1198)**: Python lexer extended with NumPy function recognition

## Key Methods

**innerstring_rules() (L67-85)**: Generates token rules for string content including format specifiers
**fstring_rules() (L87-99)**: Specialized rules for f-string content with expression handling
**analyse_text() (L409-411, L635-636, L1194-1198)**: Heuristic text analysis for lexer selection

## Token State Machine

The lexers use complex state machines with states like:
- `root`: Main parsing state
- `expr`: Expression parsing with operator precedence
- `expr-inside-fstring`: Nested expression parsing within f-strings
- Various string states (`dqs`, `sqs`, `tdqs`, `tsqs`) for different quote styles
- Import handling states (`import`, `fromimport`)

## Dependencies

- Uses `pip._vendor.pygments` framework for lexer infrastructure
- Imports `keyword` module for Python keyword validation
- Uses `unistring` for Unicode identifier patterns
- Relies on regex patterns for token matching
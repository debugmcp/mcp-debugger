# packages/adapter-rust/vendor/codelldb/darwin-x64/lldb/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py
@source-hash: 0f37870665b52314
@generated: 2026-02-09T17:57:49Z

**Primary Purpose**: Pygments lexers for Python and related languages, providing syntax highlighting for Python 2.x, Python 3.x, Cython, DG language, and NumPy code.

**Core Architecture**: Built on Pygments' RegexLexer framework, implements comprehensive token-based parsing using state machines and regex patterns.

## Main Lexer Classes

**PythonLexer (L26-414)**: Primary Python 3.x lexer with comprehensive syntax support
- Handles f-strings, string formatting, soft keywords (match/case), async/await
- Complex token state machine with nested states for string literals, expressions
- Key methods: `innerstring_rules()` (L67-85), `fstring_rules()` (L87-99), `analyse_text()` (L409-411)
- Supports extensive file patterns including .py, .pyi, .bzl, BUILD files

**Python2Lexer (L417-637)**: Legacy Python 2.x support
- Simplified token rules without f-strings or soft keywords
- Includes Python 2-specific features like backticks, long integers, print statement
- Different builtin/exception sets reflecting Python 2 standard library

**PythonConsoleLexer (L674-718)**: Interactive console session lexer
- Uses DelegatingLexer pattern to combine console prompt parsing with code highlighting
- Handles >>> prompts, ... continuations, and traceback formatting
- Configurable Python version support via `python3` option

**PythonTracebackLexer (L720-774)**: Python 3.x traceback formatting
- Parses file paths, line numbers, exception names with proper highlighting
- Supports chained exceptions and PEP 657 error markers

**Python2TracebackLexer (L777-823)**: Python 2.x traceback support

**CythonLexer (L825-1003)**: Cython/Pyrex language support
- Extends Python with C-style type annotations and cdef declarations
- Additional keywords: ctypedef, nogil, gil, cpdef, etc.
- Type parsing in angle brackets: `<type>` syntax

**DgLexer (L1005-1102)**: Functional language DG lexer
- Python-like syntax with functional programming constructs
- Custom operator handling and functional built-ins

**NumPyLexer (L1104-1198)**: Python + NumPy scientific computing
- Inherits from PythonLexer, adds NumPy-specific keyword recognition
- EXTRA_KEYWORDS set (L1119-1184) contains 300+ NumPy functions
- Override token processing to highlight NumPy built-ins

## Key Token States & Patterns

**String Handling**: Sophisticated multi-state parsing for:
- Raw strings (r"", r''), Unicode (u""), bytes (b""), f-strings
- Triple-quoted strings with escape processing
- Format string interpolation with nested expression parsing

**Expression Parsing**: Complex nested states:
- `expr-inside-fstring` (L184-203): Handles {expression} within f-strings
- `soft-keywords` (L221-234): Context-sensitive match/case pattern parsing
- Number parsing with Python 3.6+ underscore separators

**Import/Function Parsing**: Specialized states for:
- Function definitions with magic method recognition
- Class definitions and decorators
- Import statement parsing with namespace handling

## Dependencies & Integration

- Core Pygments framework: RegexLexer, DelegatingLexer, token types
- Unicode support via `pip._vendor.pygments.unistring`
- Keyword module integration for soft keyword detection
- Shebang detection utilities for Python version identification

**Notable Design Patterns**:
- State machine architecture with nested token states
- Regex-based pattern matching with lookahead/lookbehind
- Token delegation for complex nested syntax (console sessions, tracebacks)
- Inheritance hierarchy allowing feature reuse between Python versions
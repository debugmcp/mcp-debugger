# packages/adapter-rust/vendor/codelldb/darwin-x64/lldb/lib/python3.12/site-packages/pip/_internal/operations/prepare.py
@source-hash: 8e8589c0f92ea86b
@generated: 2026-02-09T17:59:50Z

## Purpose
Core distribution preparation module for pip's installation process. Handles downloading, unpacking, and validating packages from various sources (HTTP URLs, file paths, VCS repositories) while managing hash verification, caching, and metadata optimization.

## Key Classes

### `File` (L84-92)
Simple dataclass representing a downloaded file with path and optional content type. Auto-detects MIME type using `mimetypes` if not provided.

### `RequirementPreparer` (L215-732)
Main orchestrator class for preparing installation requirements. Manages:
- Download directory and build isolation settings (L218-268)
- Downloader instances for single and batch operations (L241-242)
- Memoized downloads cache to avoid re-downloading (L271)
- Hash verification requirements and lazy wheel optimization (L256-262)

## Core Functions

### `_get_prepared_distribution()` (L60-75)
Creates a distribution object from an InstallRequirement, handling build tracking and metadata preparation.

### `unpack_vcs_link()` (L78-81)
Handles VCS URL unpacking by delegating to appropriate VCS backend.

### `get_http_url()` (L94-115)
Downloads HTTP URLs to temporary directory with optional hash verification and download directory checking.

### `get_file_url()` (L118-139)
Handles file:// URLs with hash verification, supporting existing download directories.

### `unpack_url()` (L142-182)
Main unpacking dispatcher that routes to appropriate handlers based on URL type (VCS, file, HTTP). Returns File object or None for VCS links.

### `_check_download_dir()` (L185-212)
Validates previously downloaded files in download directory against expected hashes, removing mismatched files.

## RequirementPreparer Key Methods

### `prepare_linked_requirement()` (L491-527)
Primary entry point for preparing linked requirements. Implements optimization strategy:
1. Check download directory for existing valid files
2. Attempt metadata-only fetching for faster resolution
3. Fall back to full preparation if optimizations fail

### `_fetch_metadata_only()` (L358-375)
Attempts to fetch only package metadata using PEP 658 or lazy wheel techniques to avoid full downloads during dependency resolution.

### `_fetch_metadata_using_link_data_attr()` (L377-416)
Implements PEP 658 metadata fetching by downloading separate METADATA files, validating name consistency.

### `_fetch_metadata_using_lazy_wheel()` (L418-445)
Uses HTTP range requests to extract metadata from remote wheels without full download.

### `_prepare_linked_requirement()` (L559-649)
Core preparation logic handling:
- Hash validation and wheel cache verification (L565-591)
- Source directory setup (L592)
- Download/unpacking orchestration (L594-616)
- Direct URL metadata generation (L617-636)

### `prepare_linked_requirements_more()` (L529-557)
Completes preparation for requirements that were initially only metadata-fetched, using batch downloading for efficiency.

### `_complete_partial_requirements()` (L447-489)
Handles batch downloading of partially prepared requirements and unpacking of source distributions.

### `prepare_editable_requirement()` (L677-708)
Special handling for editable installs, which cannot use hash verification and require source directory management.

### `prepare_installed_requirement()` (L710-732)
Handles already-satisfied requirements, logging skip reasons and returning metadata from installed distribution.

## Dependencies
- Network layer: `Downloader`, `BatchDownloader` for HTTP operations
- VCS integration: `vcs` module for version control operations  
- Hash verification: `Hashes` class for integrity checking
- Metadata handling: `BaseDistribution`, `get_metadata_distribution`
- Build tracking: `BuildTracker` for coordinating parallel builds
- Link/URL processing: `Link` class for URL abstraction

## Architecture Notes
- Implements two-phase preparation: metadata-only optimization followed by full preparation
- Supports parallel builds through build tracking coordination
- Extensive caching to avoid redundant downloads
- Hash verification integrated throughout download pipeline
- Separates concerns between different URL types (HTTP, file, VCS, existing directories)
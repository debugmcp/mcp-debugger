# packages/adapter-rust/vendor/codelldb/linux-x64/lldb/lib/python3.12/site-packages/pip/_vendor/pygments/lexers/python.py
@source-hash: 0f37870665b52314
@generated: 2026-02-09T17:58:10Z

## Purpose
Pygments lexer module for Python and related languages. Provides comprehensive syntax highlighting and tokenization for Python 2.x/3.x source code, console sessions, tracebacks, and Python-like languages (Cython, dg, NumPy).

## Core Lexer Classes

### PythonLexer (L26-414)
Primary Python 3.x lexer. Supports comprehensive Python syntax including:
- F-strings with expression interpolation (`innerstring_rules` L67, `fstring_rules` L87)
- Pattern matching soft keywords (`soft-keywords` L221-234)
- Magic methods and variables (`magicfuncs` L276, `magicvars` L301)
- Complex string types (raw, bytes, unicode) with escape sequences
- Modern numeric formats with underscores
- Shebang detection via `analyse_text` (L409-411)

### Python2Lexer (L417-636)
Legacy Python 2.x lexer with distinct features:
- Backtick expressions (`backtick` L573-575)
- Different built-in functions (e.g., `raw_input`, `xrange`)
- Long integers (`\d+L` pattern L570)
- Python 2-specific exception types

### Console/Traceback Lexers
- **_PythonConsoleLexerBase** (L638-672): Base for console session parsing
- **PythonConsoleLexer** (L674-718): Interactive Python sessions with delegated lexing
- **PythonTracebackLexer** (L720-773): Python 3.x exception tracebacks with chained exception support
- **Python2TracebackLexer** (L777-822): Python 2.x traceback format

### Extended Language Lexers
- **CythonLexer** (L825-1002): Pyrex/Cython with C-type declarations (`cdef`, `cpdef`)
- **DgLexer** (L1005-1101): Functional programming language on CPython
- **NumPyLexer** (L1104-1198): Python + NumPy scientific computing keywords

## Key Architectural Patterns

### Token State Machine
Extensive `tokens` dictionaries define regex-based state transitions:
- Root state handles top-level constructs
- Nested states for string literals, imports, function/class names
- Context-sensitive parsing (e.g., `expr-inside-fstring` L184-203)

### String Handling Strategy
Multi-layered approach for complex Python string syntax:
- Raw strings, byte strings, unicode strings
- F-string expression parsing with balanced braces
- Format specifier recognition (`%` and `{}` style)
- Escape sequence processing per string type

### Delegated Lexing
`DelegatingLexer` pattern allows composition:
- Console lexer delegates to Python lexer for code blocks
- Traceback lexer highlights Python code within stack traces
- Enables recursive syntax highlighting in mixed content

## Dependencies
- `pip._vendor.pygments.lexer`: Core lexing framework
- `pip._vendor.pygments.token`: Token type definitions  
- `pip._vendor.pygments.util`: Utility functions (`shebang_matches`, `get_bool_opt`)
- `keyword` module: Python keyword validation

## Notable Implementation Details
- Unicode identifier support via `uni.xid_start`/`uni.xid_continue` (L65)
- Soft keyword detection with lookahead to avoid false positives (L223-228)
- F-string expression nesting with balanced parentheses tracking
- Pattern matching syntax recognition without breaking backward compatibility
# packages/adapter-rust/vendor/codelldb/linux-x64/lldb/lib/python3.12/site-packages/pip/_vendor/pygments/lexer.py
@source-hash: 2077bd79988a4c5c
@generated: 2026-02-09T18:01:44Z

## Core Purpose
Base lexer classes for Pygments syntax highlighting, providing regex-based text tokenization with state machine capabilities. Essential foundation for language-specific lexer implementations.

## Key Classes and Architecture

### LexerMeta (L37-47)
Metaclass that automatically converts `analyse_text` methods into static methods returning float values for lexer selection probability.

### Lexer (L49-285)
Base lexer class providing core tokenization interface:
- **Constructor (L140-168)**: Processes standard options (`stripnl`, `stripall`, `ensurenl`, `tabsize`, `encoding`)
- **_preprocess_lexer_input (L202-249)**: Handles encoding detection, BOM removal, newline normalization
- **get_tokens (L251-273)**: Main public interface, returns filtered token stream
- **get_tokens_unprocessed (L275-284)**: Abstract method for subclasses to implement tokenization

### DelegatingLexer (L287-318) 
Combines two lexers - processes text with language lexer first, then applies root lexer to `Other` tokens. Used by template lexers.

### RegexLexer (L664-759)
Primary regex-based lexer with state machine:
- **tokens (L697)**: Dict defining state transitions and regex rules
- **get_tokens_unprocessed (L699-758)**: Core tokenization loop with state stack management
- Uses `_tokens` (preprocessed by metaclass) for efficient matching

### RegexLexerMeta (L496-662)
Complex metaclass for RegexLexer preprocessing:
- **process_tokendef (L593-599)**: Converts token definitions into compiled regexes
- **get_tokendefs (L601-648)**: Merges token definitions from inheritance hierarchy
- **_process_state (L549-591)**: Handles state references, inheritance, and rule compilation

### ExtendedRegexLexer (L777-846)
Context-aware version of RegexLexer using LexerContext for position tracking.

### LexerContext (L761-774)
Helper object storing lexer state (text, position, state stack, end position).

## State Management Helpers

### Special State Objects
- **include (L326-330)**: References rules from another state
- **inherit (L333-340)**: Inherits rules from superclass
- **combined (L343-354)**: Merges multiple states
- **default (L468-477)**: Default state action
- **words (L480-494)**: Optimized regex for literal word lists

### Callback Functions
- **bygroups (L383-406)**: Yields multiple actions for regex groups
- **using (L418-465)**: Processes match with different lexer
- **this (L409-415)**: Special singleton for self-reference

## Utilities

### _PseudoMatch (L356-381)
Mock match object for string-based matching in callbacks.

### do_insertions (L849-911)
Combines token streams from multiple sublexers at specified positions.

### ProfilingRegexLexer (L935-961)
Performance analysis version that times regex matching operations.

## Constants and Configuration
- **line_re (L26)**: Regex for line matching
- **_encoding_map (L28-32)**: BOM to encoding mappings
- **flags (L673)**: Default regex compilation flags (MULTILINE)

## Critical Patterns
- State machine lexing with stack-based state transitions
- Metaclass preprocessing of token definitions for performance
- Encoding detection with fallback chain (guess → chardet → specified)
- Filter pipeline support for post-processing tokens
- Inheritance-based token definition merging
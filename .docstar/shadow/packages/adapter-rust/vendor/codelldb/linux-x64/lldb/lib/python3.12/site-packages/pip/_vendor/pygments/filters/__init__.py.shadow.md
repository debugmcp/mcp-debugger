# packages/adapter-rust/vendor/codelldb/linux-x64/lldb/lib/python3.12/site-packages/pip/_vendor/pygments/filters/__init__.py
@source-hash: 87f928624505a3e1
@generated: 2026-02-09T17:58:01Z

Primary purpose and responsibilities:
This module serves as the central registry and lookup system for Pygments token filters. It provides a registry of built-in filters, plugin discovery, and factory functions for filter instantiation. Filters transform token streams from lexers to modify or enhance syntax highlighting output.

Key functions:
- `find_filter_class()` (L22-29): Looks up filter classes by name, first checking built-in FILTERS registry, then plugin system
- `get_filter_by_name()` (L32-42): Factory function that instantiates a filter with options, raising ClassNotFound if filter doesn't exist
- `get_all_filters()` (L45-49): Generator yielding all available filter names from both built-in and plugin sources
- `_replace_special()` (L52-62): Utility function for regex-based token value replacement, used by multiple filter implementations

Core filter classes:
- `CodeTagFilter` (L65-94): Highlights code tags like TODO, FIXME, BUG in comments and docstrings using configurable regex matching
- `SymbolFilter` (L97-684): Converts mathematical symbols (LaTeX/Isabelle notation) to Unicode characters, with extensive symbol dictionaries for both languages
- `KeywordCaseFilter` (L687-712): Transforms keyword case (upper/lower/capitalize) for style guide compliance
- `NameHighlightFilter` (L715-753): Retypes specific name tokens (e.g., highlighting function names)
- `RaiseOnErrorTokenFilter` (L760-786): Error handling filter that raises exceptions on Error tokens
- `VisibleWhitespaceFilter` (L789-865): Makes whitespace visible using Unicode replacements (·»¶) with configurable options
- `GobbleFilter` (L868-904): Removes fixed number of leading characters per line for dedenting
- `TokenMergeFilter` (L907-928): Merges consecutive tokens of same type for optimization

Key dependencies:
- `pip._vendor.pygments.token`: Token type constants and string_to_tokentype conversion
- `pip._vendor.pygments.filter`: Base Filter class
- `pip._vendor.pygments.util`: Option parsing utilities (get_list_opt, get_int_opt, etc.)
- `pip._vendor.pygments.plugin`: Plugin discovery system via find_plugin_filters()

Global registry:
- `FILTERS` dict (L931-940): Maps filter names to classes for lookup system

Architecture patterns:
- Factory pattern for filter instantiation with option validation
- Plugin architecture for extensible filter discovery
- Stream processing pattern - all filters implement filter(lexer, stream) yielding transformed (ttype, value) pairs
- Extensive use of option parsing utilities for consistent configuration handling

Critical invariants:
- All filters must inherit from Filter base class and implement filter() method
- Token streams are (token_type, value) tuples that must be preserved or transformed appropriately
- Filter options are validated using get_*_opt utility functions
- Symbol dictionaries use Unicode escape sequences for mathematical notation
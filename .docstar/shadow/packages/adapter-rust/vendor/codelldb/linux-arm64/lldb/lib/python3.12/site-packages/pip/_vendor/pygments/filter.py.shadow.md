# packages/adapter-rust/vendor/codelldb/linux-arm64/lldb/lib/python3.12/site-packages/pip/_vendor/pygments/filter.py
@source-hash: 8f968b33d6bdc12c
@generated: 2026-02-09T18:00:39Z

## Purpose
This module provides the filtering infrastructure for the Pygments syntax highlighting library. It implements a pipeline system for applying transformations to token streams produced by lexers.

## Key Components

### Functions
- `apply_filters(stream, filters, lexer=None)` (L12-22): Core pipeline function that chains multiple filters together. Takes a token stream and applies each filter in sequence, with each filter receiving the output of the previous one.
- `simplefilter(f)` (L25-38): Decorator that converts a regular function into a Filter class. Dynamically creates a new class inheriting from FunctionFilter with the decorated function bound to it.

### Classes
- `Filter` (L41-52): Abstract base class for all filters. Stores filter options in constructor and defines the interface with an abstract `filter(lexer, stream)` method that must be implemented by subclasses.
- `FunctionFilter(Filter)` (L54-71): Abstract intermediate class used by the `simplefilter` decorator. Contains a `function` attribute that gets bound during dynamic class creation and validates that the function is properly bound during initialization.

## Architecture Patterns
- **Pipeline Pattern**: Filters are chained together in sequence, with each filter transforming the token stream
- **Generator-based Processing**: Uses `yield from` for memory-efficient streaming of tokens
- **Dynamic Class Creation**: The `simplefilter` decorator creates classes at runtime using the `type()` constructor
- **Template Method Pattern**: Base Filter class defines the interface while concrete implementations provide the behavior

## Key Relationships
- Filters expect to receive and produce streams of `(token_type, value)` tuples
- The lexer parameter is optional and passed through the entire filter chain
- Filter options are stored as instance attributes for configuration

## Critical Invariants
- All filters must implement the `filter(lexer, stream)` method
- FunctionFilter subclasses must have a bound `function` attribute
- Token streams maintain the `(token_type, value)` tuple format throughout the pipeline
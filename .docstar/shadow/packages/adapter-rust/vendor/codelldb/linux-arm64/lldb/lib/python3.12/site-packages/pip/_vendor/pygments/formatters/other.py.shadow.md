# packages/adapter-rust/vendor/codelldb/linux-arm64/lldb/lib/python3.12/site-packages/pip/_vendor/pygments/formatters/other.py
@source-hash: 80fc6493905d0335
@generated: 2026-02-09T17:57:48Z

## pygments.formatters.other.py

**Purpose**: Provides specialized Pygments formatters for minimal output scenarios and testing infrastructure.

**Key Components**:

### NullFormatter (L19-33)
- **Purpose**: Passes through tokenized text without any formatting transformations
- **Configuration**: 
  - Name: 'Text only', aliases: ['text', 'null']
  - File extensions: ['*.txt']
- **Key Method**: `format()` (L27-33) - Writes raw token values to output, handling encoding if specified
- **Use Case**: When syntax highlighting is not desired but tokenization processing is still needed

### RawTokenFormatter (L36-116)  
- **Purpose**: Serializes token streams to a parseable raw format for storage/transmission
- **Output Format**: `tokentype<TAB>repr(tokenstring)\n` for each token
- **Configuration**:
  - Name: 'Raw tokens', aliases: ['raw', 'tokens'] 
  - File extensions: ['*.raw']
  - Forces ASCII encoding regardless of input encoding settings
- **Key Features**:
  - Compression support (gz/bz2) via `compress` option (L68-69)
  - Error token highlighting via `error_color` option (L70-78)
  - Binary output requirement validation (L82-85)
- **Key Method**: `format()` (L80-116) - Handles compression setup and token serialization with optional error highlighting

### TestcaseFormatter (L130-161)
- **Purpose**: Generates Python test code from token streams for lexer testing
- **Output**: Valid Python test function with token assertions
- **Template Structure**: Uses `TESTCASE_BEFORE` (L119-123) and `TESTCASE_AFTER` (L124-127) constants
- **Encoding**: Restricted to None or UTF-8 only (L141-142)
- **Key Method**: `format()` (L144-161) - Builds test case by collecting tokens into assertion format

**Dependencies**:
- `Formatter` base class from `pip._vendor.pygments.formatter`
- `get_choice_opt` utility for option validation
- `Token` for token type checking
- `colorize` for error highlighting in RawTokenFormatter

**Architecture Notes**:
- All formatters follow the standard Pygments formatter interface
- RawTokenFormatter is bidirectional - output can be parsed by RawTokenLexer
- TestcaseFormatter enables automated test generation for lexer development
- Compression handling uses lazy imports and functional programming patterns